{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import time\n",
    "import numpy as np\n",
    "os.chdir('/home/idies/workspace/Temporary/raddick/cra_scratch/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "tracts_df = pandas.read_csv('tracts_df.csv', encoding='utf-8', index_col='rownumber')\n",
    "e = time.time()\n",
    "print('Loaded {0:,.0f} rows in {1:,.0f} seconds.'.format(len(tracts_df), e-s))\n",
    "tracts_df_bk = tracts_df\n",
    "tracts_df.sample(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('reading from backup...')\n",
    "c = 0\n",
    "s = time.time()\n",
    "tracts_df = tracts_df_bk\n",
    "print('getting institution name from respondentID...')\n",
    "respondents_df = pandas.read_csv('/home/idies/workspace/Storage/raddick/raddick_cra/respondentid.csv', encoding='utf-8', index_col='respondentID')\n",
    "print('Loaded respondentIDs (n = {0:,.0f}).'.format(len(respondents_df['institution_name'].drop_duplicates())))\n",
    "\n",
    "print('\\nAdding institution (from respondentID)...')\n",
    "tracts_df = tracts_df.join(respondents_df, how='left', on='respondentID')\n",
    "# There are only 87 unique institutions represented?\n",
    "print('Found institutions for {0:,.0f} ({1:,.0f} unique).'.format(len(tracts_df['institution_name'].notnull()), len(tracts_df['institution_name'].drop_duplicates().notnull())))\n",
    "tracts_df['institution_name'] = tracts_df['institution_name'].fillna('Unknown')\n",
    "\n",
    "print('\\nAssigning codes...')\n",
    "s = time.time()\n",
    "print('agency_code -> agency...')\n",
    "tracts_df.assign(agency='')\n",
    "tracts_df.loc[tracts_df['agency_code'] == 1, 'agency'] = 'OCC'\n",
    "tracts_df.loc[tracts_df['agency_code'] == 2, 'agency'] = 'FRS'\n",
    "tracts_df.loc[tracts_df['agency_code'] == 3, 'agency'] = 'FDIC'\n",
    "tracts_df.loc[tracts_df['agency_code'] == 4, 'agency'] = 'OTS'\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Assigned agency names for {0:,.0f} rows in {1:,.0f} seconds.'.format(len(tracts_df[tracts_df['agency'] != '']), e-s))\n",
    "\n",
    "print('income_group_total -> income_group')\n",
    "s = time.time()\n",
    "tracts_df['income_group_total'] = pandas.to_numeric(tracts_df['income_group_total'], errors='coerce')\n",
    "\n",
    "tracts_df.assign(income_group='')\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 1, 'income_group'] = '< 10% of Median Family Income (MFI)'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 2, 'income_group'] = '10% to 20% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 3, 'income_group'] = '20% to 30% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 4, 'income_group'] = '30% to 40% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 5, 'income_group'] = '40% to 50% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 6, 'income_group'] = '50% to 60% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 7, 'income_group'] = '60% to 70% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 8, 'income_group'] = '70% to 80% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 9, 'income_group'] = '80% to 90% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 10, 'income_group'] = '90% to 100% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 11, 'income_group'] = '100% to 110% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 12, 'income_group'] = '110% to 120% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 13, 'income_group'] = '> 120% of MFI'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 14, 'income_group'] = 'MFI not known (income percentage = 0)'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 15, 'income_group'] = 'Tract not Known (reported as NA)'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 101, 'income_group'] = 'Low Income (< 50% of MFI) - excluding 0)'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 102, 'income_group'] = 'Moderate Income (50% to 80% of MFI)'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 103, 'income_group'] = 'Middle Income (80% to 120% of MFI)'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 104, 'income_group'] = 'Upper Income (> 120% of MFI)'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 105, 'income_group'] = 'Income Not Known (0)'\n",
    "tracts_df.loc[tracts_df['income_group_total'] == 106, 'income_group'] = 'Tract not Known (NA)'\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Assigned income group names for {0:,.0f} rows in {1:,.0f} seconds.'.format(len(tracts_df[tracts_df['income_group'] != '']), e-s))\n",
    "\n",
    "\n",
    "print('state -> state_name...')\n",
    "s = time.time()\n",
    "statecodes_df = pandas.read_csv(\n",
    "    '/home/idies/workspace/Storage/raddick/persistent/cra/metadata/statecodes.csv', \n",
    "    encoding='utf-8', index_col='STATE')\n",
    "statecodes_df = statecodes_df.rename(columns={'STUSAB': 'state_name'})\n",
    "statecodes_df.index.name = 'state'\n",
    "tracts_df = tracts_df.join(statecodes_df, how='left', on='state')\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Assigned state names for {0:,.0f} rows in {1:,.0f} seconds.'.format(len(tracts_df[tracts_df['state_name'].notnull()]), e-s))\n",
    "\n",
    "print('county -> county_name...')\n",
    "s = time.time()\n",
    "countycodes_df = pandas.read_csv(\n",
    "    '/home/idies/workspace/Storage/raddick/persistent/cra/metadata/countycodes.csv', \n",
    "    encoding='utf-8')\n",
    "countycodes_df = countycodes_df.drop('state_name', axis=1)\n",
    "countycodes_df.assign(fips_class_description='')\n",
    "countycodes_df.loc[countycodes_df['fips_class_code'] == 'H1', 'fips_class_description'] = 'active county'\n",
    "countycodes_df.loc[countycodes_df['fips_class_code'] == 'H4', 'fips_class_description'] = 'inactive county'\n",
    "countycodes_df.loc[countycodes_df['fips_class_code'] == 'H5', 'fips_class_description'] = 'Alaska census area'\n",
    "countycodes_df.loc[countycodes_df['fips_class_code'] == 'H6', 'fips_class_description'] = 'part of another entity'\n",
    "countycodes_df.loc[countycodes_df['fips_class_code'] == 'C7', 'fips_class_description'] = 'independent city'\n",
    "countycodes_df = countycodes_df.set_index(['state', 'county'])\n",
    "\n",
    "tracts_df = tracts_df.join(countycodes_df['county_name'], how='left', on=['state', 'county'])\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('Assigned county names for {0:,.0f} rows in {1:,.0f} seconds.'.format(len(tracts_df[tracts_df['county_name'].notnull()]), e-s))\n",
    "\n",
    "s = time.time()\n",
    "print('\\nreplacing NA with -1 in...')\n",
    "print('msa...')\n",
    "tracts_df.loc[tracts_df['msa'] == 'NA  ', 'msa'] = '-1'\n",
    "print('assessment_area_number...')\n",
    "tracts_df.loc[tracts_df['assessment_area_number'] == 'NA  ', 'assessment_area_number'] = '-1'\n",
    "\n",
    "print('\\nconverting to numeric...')\n",
    "print('msa...')\n",
    "tracts_df['msa'] = pandas.to_numeric(tracts_df['msa'], errors='coerce')\n",
    "print('assessment_area_number...')\n",
    "tracts_df['assessment_area_number'] = pandas.to_numeric(tracts_df['assessment_area_number'], errors='coerce')\n",
    "\n",
    "print('\\nReplacing -1 with NaN in...')\n",
    "print('msa...')\n",
    "tracts_df.loc[tracts_df['msa'] == -1, 'msa'] = np.nan\n",
    "print('assessment_area_number...')\n",
    "tracts_df.loc[tracts_df['assessment_area_number'] == -1, 'assessment_area_number'] = np.nan\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "s = time.time()\n",
    "print('\\nBacking up...')\n",
    "tracts_df_bk = tracts_df\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "print('Done in {0:,.0f} seconds total.'.format(c))\n",
    "tracts_df.sample(3).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MATCH TO METRO AREAS...')\n",
    "c = 0\n",
    "s = time.time()\n",
    "print('Reading from backup...')\n",
    "tracts_df = tracts_df_bk\n",
    "print('Overall {0:,.0f} rows.'.format(len(tracts_df)))\n",
    "print('MSA values in {0:,.0f} rows.'.format(len(tracts_df[tracts_df['msa'].notnull()])))\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "s = time.time()\n",
    "msa_df = pandas.read_csv(\n",
    "    '/home/idies/workspace/Storage/raddick/persistent/cra/metadata/msacodes.csv', \n",
    "    encoding='utf-8', low_memory=False)\n",
    "msa_mathcer_df = msa_df[['msa_code', 'msa_title']][msa_df['msa_code'].notnull()].drop_duplicates()\n",
    "msa_mathcer_df = msa_mathcer_df.set_index('msa_code')\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "print('\\nRead {0:,.0f} msacodes ({1:,.0f} distinct) in {2:,.0f} seconds.'.format(len(msa_df[msa_df['msa_code'].notnull()]), len(msa_mathcer_df), e-s))\n",
    "\n",
    "print('Will match to a list of {0:,.0f} distinct msa_codes...'.format(len(msa_mathcer_df)))\n",
    "\n",
    "s = time.time()\n",
    "tracts_df = tracts_df[tracts_df['msa'].notnull()].join(msa_mathcer_df, how='left', on='msa')\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "print('\\nMatched {0:,.0f} rows to MSA codes in {1:,.0f} seconds.'.format(len(tracts_df[tracts_df['msa_title'].notnull()]), e-s))\n",
    "\n",
    "print('{0:,.0f} rows remain to be matched...'.format(len(tracts_df[(tracts_df['msa_title'].isnull()) & (tracts_df['msa'].notnull())])))\n",
    "\n",
    "#print('\\nThere are {0:,.0f} CBSA codes found in msa_df that do not have MSA equivalents ({1:,.0f} distinct).'.format(len(msa_df[(msa_df['cbsa_code'].notnull()) & (msa_df['msa_code'].isnull())]), len(msa_df['cbsa_code'][(msa_df['cbsa_code'].notnull()) & (msa_df['msa_code'].isnull())].drop_duplicates())))\n",
    "print('\\nThere are {0:,.0f} CBSA codes found in msa_df ({1:,.0f} distinct).'.format(len(msa_df[(msa_df['cbsa_code'].notnull())]), len(msa_df['cbsa_code'][(msa_df['cbsa_code'].notnull())].drop_duplicates())))\n",
    "\n",
    "cbsa_matcher_df = msa_df[['cbsa_code', 'cbsa_title']][(msa_df['cbsa_code'].notnull())].drop_duplicates() #& (msa_df['msa_code'].isnull())].drop_duplicates()\n",
    "cbsa_matcher_df = cbsa_matcher_df.set_index('cbsa_code')\n",
    "\n",
    "print('Will match to a list of {0:,.0f} distinct cbsa_codes...'.format(len(cbsa_matcher_df)))\n",
    "\n",
    "s = time.time()\n",
    "tracts_df = tracts_df[tracts_df['msa'].notnull()].join(cbsa_matcher_df, how='left', on='msa')\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "print('\\nMatched {0:,.0f} rows to CBSA codes in {1:,.0f} seconds.'.format(len(tracts_df[tracts_df['cbsa_title'].notnull()]), e-s))\n",
    "\n",
    "print('\\nThere are {0:,.0f} rows with either MSA or CBSA titles, and {1:,.0f} rows with both.'.format(len(tracts_df[(tracts_df['msa_title'].notnull()) | (tracts_df['cbsa_title'].notnull())]), len(tracts_df[(tracts_df['msa_title'].notnull()) & (tracts_df['cbsa_title'].notnull())])))\n",
    "\n",
    "print('\\nRenaming columns...')\n",
    "tracts_df = tracts_df.rename(columns={'msa_title': 'msa_name'})\n",
    "tracts_df = tracts_df.rename(columns={'cbsa_title': 'cbsa_name'})\n",
    "\n",
    "print('\\nBacking up...')\n",
    "tracts_df_bk = tracts_df\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "print('\\nDONE in {0:,.0f} seconds.'.format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSA got converted back to object for some reason, so make it numeric again...\n",
    "s = time.time()\n",
    "print('\\nconverting to numeric...')\n",
    "print('msa...')\n",
    "tracts_df['msa'] = pandas.to_numeric(tracts_df['msa'], errors='coerce')\n",
    "\n",
    "print('\\nwriting outfile...')\n",
    "tracts_df.to_csv('tracts_processed.csv', encoding='utf-8')\n",
    "\n",
    "e = time.time()\n",
    "c = c + (e-s)\n",
    "\n",
    "print('\\nDONE in {0:,.0f} seconds.'.format(e-s))\n",
    "#tracts_df.groupby('msa').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "df = pandas.read_csv('tracts_processed.csv', encoding='utf-8', index_col='rownumber')\n",
    "e = time.time()\n",
    "print('Loaded in {0:,.0f} seconds.'.format(e-s))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
